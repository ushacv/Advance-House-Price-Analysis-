{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.linear_model import Lasso, BayesianRidge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =pd.read_csv('X_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating X and Y variables for Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_model(model, X_train=X_train, y_train=y_train):\n",
    "    cv = KFold(n_splits = 3, shuffle=True, random_state = 45)\n",
    "    r2 = make_scorer(r2_score)\n",
    "    r2_val_score = cross_val_score(model, X_train, y_train, cv=cv, scoring = r2)\n",
    "    score = [r2_val_score.mean()]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-8.543231864770832e+21]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "LR = linear_model.LinearRegression()\n",
    "test_model(LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso and ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8454970710873354]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdg = linear_model.Ridge(alpha=0.005, random_state = 4)\n",
    "test_model(rdg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8524635789112677]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = linear_model.Lasso(alpha=1e-4)\n",
    "test_model(lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8639497050512198]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENet = linear_model.ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3)\n",
    "test_model(ENet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8692210493859426]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svr_reg = SVR(kernel='rbf')\n",
    "test_model(svr_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6691992174595726]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dt_reg = DecisionTreeRegressor(random_state=21)\n",
    "test_model(dt_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8657457964650583]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators = 1000, random_state=51)\n",
    "test_model(rf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging & Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8660357027386202]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br_reg = BaggingRegressor(n_estimators=1000, random_state=51)\n",
    "test_model(br_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8844778922047046]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_reg = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1, loss='ls', random_state=51)\n",
    "test_model(gbr_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:49:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"bbooster\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[07:49:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"bbooster\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[07:49:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"bbooster\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8583970509260753]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "xgb_reg = xgboost.XGBRegressor(bbooster='gbtree', random_state=51)\n",
    "test_model(xgb_reg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tunning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can all algorithm gives almost same accuracy hence will perform Hyperparameter Tunning to increase accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8709721519881256"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'rbf'],\n",
    "         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "         'C': [0.1, 1, 10, 100, 1000],\n",
    "         'epsilon': [1, 0.2, 0.1, 0.01, 0.001, 0.0001]}\n",
    "rand_search = RandomizedSearchCV(svr_reg, param_distributions=params, n_jobs=-1, cv=10)\n",
    "rand_search.fit(X_train, y_train)\n",
    "rand_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'sigmoid', 'gamma': 0.001, 'epsilon': 0.001, 'C': 1000}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.87139754866591]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_reg1 = SVR(kernel= 'sigmoid', gamma = 0.001, epsilon = 0.001, C = 1000)\n",
    "test_model(svr_reg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can see there is 1 % accuracy increase after tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoosting  Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=GradientBoostingRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'alpha': [0.005, 0.05],\n",
       "                                        'criterion': ['friedman_mse', 'mse',\n",
       "                                                      'mae'],\n",
       "                                        'learning_rate': [0.2, 0.1, 0.01, 0.05],\n",
       "                                        'loss': ['ls', 'lad', 'huber',\n",
       "                                                 'quantile'],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [0.05, 0.5],\n",
       "                                        'min_samples_split': [2, 3],\n",
       "                                        'n_estimators': range(99, 2001, 80)},\n",
       "                   random_state=51, return_train_score=True,\n",
       "                   scoring='neg_mean_absolute_error', verbose=11)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_reg2 = GradientBoostingRegressor()\n",
    "params = { 'loss': ['ls', 'lad', 'huber', 'quantile'], 'n_estimators': range(99, 2001, 80),\n",
    "              'criterion' :['friedman_mse', 'mse', 'mae'], 'min_samples_split': [2,3], 'min_samples_leaf': [0.05,0.5],\n",
    "              'max_features':['auto', 'sqrt', 'log2'],'alpha':[0.005, 0.05],\n",
    "              'learning_rate': [0.2, 0.1, 0.01, 0.05] } \n",
    "\n",
    "rand_search_gbr2 = RandomizedSearchCV(estimator = gbr_reg2, param_distributions=params, n_iter=100, n_jobs=-1, \n",
    "                                     cv=10, verbose=11, random_state=51, return_train_score =True, \n",
    "                                     scoring='neg_mean_absolute_error') \n",
    "\n",
    "rand_search_gbr2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08313443655885186"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_gbr2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1699,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 0.05,\n",
       " 'max_features': 'sqrt',\n",
       " 'loss': 'ls',\n",
       " 'learning_rate': 0.05,\n",
       " 'criterion': 'mae',\n",
       " 'alpha': 0.05}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_gbr2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "C:\\Users\\harsha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "C:\\Users\\harsha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8901541473603126]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_reg2 = GradientBoostingRegressor(n_estimators=1699, random_state=51, min_samples_split= 2,\n",
    "                                  min_samples_leaf = 0.05, max_features = 'sqrt', loss= 'lad',learning_rate= 0.05,\n",
    "                                   criterion = 'mae', alpha = 0.05)\n",
    "test_model(gbr_reg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we can see all alogorithm gives almost same accuracy , among all Linear Regression is giving more accuracy hence our best model is \"GradientBoosting\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# will still check with feature selection ,can improve accuracy or not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for that we will define our X and Y varible again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =pd.read_csv('X_train.csv')\n",
    "test =pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import feature obtained after Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature = ['LotShape', 'BldgType', 'OverallQual', 'YearBuilt', 'YearRemodAdd',\n",
    "       'ExterQual', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'HeatingQC',\n",
    "       'CentralAir', '1stFlrSF', 'GrLivArea', 'FullBath', 'KitchenQual',\n",
    "       'Functional', 'Fireplaces', 'GarageType', 'GarageFinish', 'GarageCars','GarageArea','GarageYrBlt',\n",
    "       'PavedDrive', 'SaleCondition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[selected_feature]\n",
    "X_test = test[selected_feature]\n",
    "y_train = train.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_train=X_train, y_train=y_train):\n",
    "    cv = KFold(n_splits = 3, shuffle=True, random_state = 45)\n",
    "    r2 = make_scorer(r2_score)\n",
    "    r2_val_score = cross_val_score(model, X_train, y_train, cv=cv, scoring = r2)\n",
    "    score = [r2_val_score.mean()]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8563746218352245]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRF = linear_model.LinearRegression()\n",
    "test_model(LRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso and ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8563828583043618]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdgF = linear_model.Ridge(alpha=0.005, random_state = 4)\n",
    "test_model(rdgF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8566069513078524]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoF = linear_model.Lasso(alpha=1e-4)\n",
    "test_model(lassoF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8568969007536089]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENetF = linear_model.ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3)\n",
    "test_model(ENetF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8496693475665772]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svr_regF = SVR(kernel='rbf')\n",
    "test_model(svr_regF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8561674394928668]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf_regF = RandomForestRegressor(n_estimators = 1000, random_state=51)\n",
    "test_model(rf_regF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging & Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8563557064429409]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br_regF = BaggingRegressor(n_estimators=1000, random_state=51)\n",
    "test_model(br_regF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8569433944817103]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_regF = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1, loss='ls', random_state=51)\n",
    "test_model(gbr_regF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:02:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"bbooster\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:02:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"bbooster\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:02:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"bbooster\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8414048834228062]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "xgb_regF = xgboost.XGBRegressor(bbooster='gbtree', random_state=51)\n",
    "test_model(xgb_regF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see all model accuracy has increased after Feature selection and all model giving almost same accuracy and in which , \n",
    "GradientBoostingregressor, Lasso, Ridge, Elasticnet are being remain high performance model throughout test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But to finalise model , GradientBoosting Model gives excellent accuracy in over all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "gbr_reg2.fit(X_train,y_train)\n",
    "y_pred = np.exp(gbr_reg2.predict(X_test)).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Model Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.79897599, 11.96888619, 12.19088503, ..., 12.01262345,\n",
       "       11.72899386, 12.38439546])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pickle.dump(gbr_reg2, open('model_house_price_prediction.csv', 'wb'))\n",
    "model_house_price_prediction = pickle.load(open('model_house_price_prediction.csv', 'rb'))\n",
    "model_house_price_prediction.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "C:\\Users\\harsha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n",
      "C:\\Users\\harsha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8901541473603126]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model_house_price_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingRegressor Accuracy  = 89.013% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
